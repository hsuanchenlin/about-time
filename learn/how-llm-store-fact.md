how llm store fact
--
resource:
https://www.youtube.com/watch?v=9-Jl0dxWQs8&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=8

--

# Known
- ReLu
An activation function to transform linear value to be 1 and 0


# Unknown
- What are up-projection and down-projection
- Explain the superposition concept