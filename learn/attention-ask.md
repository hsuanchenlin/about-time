# Questions from attention

**Source:** `learn/attention.md`

**Known Items:** 5

---

## Question 1

**Q:** low rank transformation. why the part of the matrix could be dropped?

**A:** _[Your answer here]_

---

## Question 2

**Q:** cross attention. is it important compared to self-attention? can't understand the difference

**A:** _[Your answer here]_

---

## Question 3

**Q:** multi-headed attention. dont'understand it

**A:** _[Your answer here]_

---

## Question 4

**Q:** output matrix. no idea either

**A:** _[Your answer here]_

---


## Instructions

1. Fill in your answers above
2. Rename this file to `attention-response.md`
3. Commit and push to trigger AI elaboration
