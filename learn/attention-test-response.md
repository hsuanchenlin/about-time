# My Response to attention-ask.md

## Answer 1
This is my answer to the first question about attention mechanisms.

## Answer 2
This is my answer about transformers.

## Known Unknown
- How does multi-head attention differ from single-head attention in practice?
- What are the computational trade-offs of increasing the number of attention heads?
